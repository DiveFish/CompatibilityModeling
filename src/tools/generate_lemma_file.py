"""
The file generated by this script is the same candidate file that 
was generated by src.pp_head_extraction.extract_ambiguous_pp.py.
The only difference is that the file contains the lemmas of all nouns
instead of the full forms of the nouns.

The lemma file is created on the basis of the candidate file with the
full form.
The lemma information comes from a TÃ¼ba conll file.
"""

import argparse
import csv
from pyconll.load import iter_from_file

from src.pp_head_extraction.graph import AdjacentTokens
from src.pp_head_extraction.graph import Direction
from src.pp_head_extraction.graph import sentence_to_graph


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument("tueba_file", help="Input Tueba CoNLL file")
    parser.add_argument("candidate_file", help="Input file with candidate heads")
    parser.add_argument("lemma_out_file", help="Output statistics file.")

    args = parser.parse_args()

    with open(args.candidate_file) as cand_file:
        reader = csv.reader(cand_file, delimiter="\t")
        pp_lines = {}
        for line in reader:
            sent_id = int(line[0])
            if pp_lines.get(sent_id):
                pp_lines[sent_id].append(line)
            else:
                pp_lines[sent_id] = [line]

    with open(args.lemma_out_file, "w") as lemma_file:
        writer = csv.writer(lemma_file, delimiter="\t")
        for sent_id, sentence in enumerate(iter_from_file(args.tueba_file), start=1):

            # This is necessary for the dev set because entry 8930 was removed from the dev set.
            if "dev" in args.tueba_file and sent_id > 8930:
                sent_id += 1
            if "train" in args.tueba_file and sent_id > 18118:
                sent_id += 1

            form2lemma = {}

            graph = sentence_to_graph(sentence)
            # The graph is traversed from word 0 to the last word.
            for current_id in AdjacentTokens(graph, 0, Direction.Succeeding):
                # Store the current token.
                token = graph.vs.find(name=current_id)["token"]
                form2lemma[token.form] = token.lemma
            try:
                sent_pp_lines = pp_lines[sent_id]
            except KeyError:
                continue
            for pp_line in sent_pp_lines:
                current_idx = 1
                new_line = pp_line
                # Care about preposition.
                prep = pp_line[current_idx]
                prep_lemma = form2lemma[prep]
                new_line[current_idx] = prep_lemma
                # Care about PP object.
                current_idx += 3
                pp_obj = pp_line[current_idx]
                pp_obj_lemma = form2lemma[pp_obj]
                new_line[current_idx] = pp_obj_lemma
                current_idx += 3
                while current_idx < len(pp_line) - 1:
                    cand = pp_line[current_idx]
                    cand_lemma = form2lemma[cand]
                    new_line[current_idx] = cand_lemma
                    current_idx += 6

                writer.writerow(new_line)
